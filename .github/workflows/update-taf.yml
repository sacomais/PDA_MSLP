name: Update Data (NOTAMs Hourly / TAF Daily)

on:
  schedule:
    - cron: '0 * * * *' # Cada hora
  workflow_dispatch:

jobs:
  update:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GH_PAT }}

      - name: Setup folders
        run: mkdir -p public/data

      # ------------------------------------------------------------------
      # 1. NOTAMS: FAA PILOTWEB via CHROME (SELENIUM)
      # Simula un navegador real para evitar bloqueos de seguridad.
      # ------------------------------------------------------------------
      - name: Descargar NOTAMs (Chrome Headless)
        run: |
          # 1. Instalar Selenium (Controlador de navegador)
          pip install selenium webdriver-manager beautifulsoup4

          # 2. Crear script de Python que controla Chrome
          cat <<EOF > scrape_chrome.py
          from selenium import webdriver
          from selenium.webdriver.chrome.options import Options
          from bs4 import BeautifulSoup
          import json
          import re
          import time
          import sys

          # Configurar Chrome en modo "Headless" (sin pantalla visible)
          options = Options()
          options.add_argument("--headless") 
          options.add_argument("--no-sandbox")
          options.add_argument("--disable-dev-shm-usage")
          options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")

          print("1. Iniciando navegador Chrome...")
          driver = webdriver.Chrome(options=options)

          try:
              # PASO A: Ir a la Home de PilotWeb para obtener cookies legítimas
              print("2. Accediendo a FAA PilotWeb (Home)...")
              driver.get("https://pilotweb.nas.faa.gov/PilotWeb/")
              time.sleep(3) # Esperar carga inicial

              # PASO B: Navegar directo a la URL de resultados de MSLP
              # Al tener cookies del paso A, ya no nos redirige.
              print("3. Buscando resultados para MSLP...")
              target_url = "https://pilotweb.nas.faa.gov/PilotWeb/notamRetrievalByICAOAction.do?method=displayByICAOs&reportType=REPORT&actionType=notamRetrievalByICAOs&retrieveLocId=MSLP&formatType=ICAO"
              driver.get(target_url)
              time.sleep(2)

              # PASO C: Extraer el HTML resultante
              html_content = driver.page_source
              
              # Usar BeautifulSoup para leer el HTML
              soup = BeautifulSoup(html_content, 'html.parser')
              text = soup.get_text(separator=' ', strip=True)
              
              print("4. Procesando texto extraído...")
              
              # Buscar patrones de NOTAM: Letra + 4 digitos + / + 2 digitos (Ej: A0459/25)
              # Regex: Busca el ID y captura el contenido hasta el próximo ID
              pattern = re.compile(r'([A-Z]\d{4}/\d{2})(.*?)(?=[A-Z]\d{4}/\d{2}|End of Report|Account|$)', re.DOTALL)
              matches = pattern.findall(text)

              notams_list = []
              
              for match in matches:
                  nid = match[0].strip()
                  content = match[1].strip()
                  
                  # Limpieza básica
                  full_msg = f"{nid} {content}"
                  
                  # Filtro de ruido
                  if len(content) > 10 and "Account" not in nid:
                      notams_list.append({
                          "notamNumber": nid,
                          "icaoMessage": full_msg,
                          "startDate": "2025-01-01T00:00:00Z" # Fecha dummy
                      })

              print(f"✅ ÉXITO: Se encontraron {len(notams_list)} NOTAMs.")
              
              # Guardar JSON
              output = { "notamList": notams_list }
              with open('public/data/notams.json', 'w') as f:
                  json.dump(output, f, indent=2)

          except Exception as e:
              print(f"❌ Error durante el scraping: {e}")
              # Generar vacío por seguridad
              with open('public/data/notams.json', 'w') as f:
                  json.dump({"notamList": []}, f)
              sys.exit(1)
              
          finally:
              driver.quit()
          EOF

          # 3. Ejecutar
          python scrape_chrome.py
          
          echo "Vista previa:"
          head -n 20 public/data/notams.json

      # ------------------------------------------------------------------
      # 2. TAF y EXCEL: SOLO A LAS 05:00 UTC (O MANUAL)
      # ------------------------------------------------------------------
      - name: Descargar TAF y Excel (Condicional)
        run: |
          CURRENT_HOUR=$(date -u +%H)
          
          if [ "$CURRENT_HOUR" == "05" ] || [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "Actualizando TAF y Excel..."
            
            # TAF
            curl -s "https://tgftp.nws.noaa.gov/data/forecasts/taf/stations/MSLP.TXT" -o tmp_taf.txt
            taf_block=$(awk '/^TAF MSLP/{flag=1} flag{print} /^$/{if(flag){exit}}' tmp_taf.txt)
            if echo "$taf_block" | head -1 | grep -qE "03[0-5][0-9]Z"; then
              echo "$taf_block" > public/data/taf-today.txt
            else
              echo "NIL" > public/data/taf-today.txt
            fi

            # EXCEL
            file_id="1VCS87YR2-O4tJLaJJMVAZtBTPYEQG9fQ"
            curl -L "https://drive.google.com/uc?export=download&id=${file_id}" -o public/operaciones.xlsx
          else
            echo "Se salta la actualización de TAF/Excel (Solo 05 UTC)."
          fi

      # ------------------------------------------------------------------
      # 3. GUARDAR CAMBIOS
      # ------------------------------------------------------------------
      - name: Configurar Git y Guardar
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add public/data/taf-today.txt public/operaciones.xlsx public/data/notams.json || true
          
          if git diff --cached --quiet; then
            echo "No hay cambios."
          else
            git commit -m "Auto-update data $(date -u '+%H:%M UTC')"
            git push origin main
          fi
